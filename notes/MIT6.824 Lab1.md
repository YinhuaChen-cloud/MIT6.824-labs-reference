# MIT6.824 Lab1

在本实验中，需要构建一个简单的分布式系统MapReduce，用户需要根据任务的需求，将任务拆分为Map和Reduce两个部分，并编写对应的函数用于使用系统接口。通过这种方式，用户可以在忽略并行化、容错等细节的条件下完成任务的分布式并发计算。

## MapReduce工作原理

### Map及Reduce函数

![Lab1_figure1](https://github.com/jlu-xiurui/MIT6.824-labs/blob/master/noteFigures/Lab1_figure1.png)

在MapReduce系统中，用户需要定义自己的 `map` 和 `reduce` 函数以完成上图任务，其中 `map` 函数获取系统的输入<文件名，文件文本>键值对，将其转化为一系列的中间键值对并存入中间文件；`reduce` 函数获取中间键值对中的某一键以及对应的所有值，并在进行一系列处理后得到任务输出。下面是一组 `map` 和 `reduce`函数的实例：

```go
func Map(filename string, contents string) []mr.KeyValue {
	// function to detect word separators.
	ff := func(r rune) bool { return !unicode.IsLetter(r) }

	// split contents into an array of words.
	words := strings.FieldsFunc(contents, ff)

	kva := []mr.KeyValue{}
	for _, w := range words {
		kv := mr.KeyValue{w, "1"}
		kva = append(kva, kv)
	}
	return kva
}

//
// The reduce function is called once for each key generated by the
// map tasks, with a list of all the values created for that key by
// any map task.
//
func Reduce(key string, values []string) string {
	// return the number of occurrences of this word.
	return strconv.Itoa(len(values))
}
```

上述函数组合的作用为计算文件文本中各单词的数目，其中 `Map` 函数解析文件文本中的单词，对于文本中的每一个单词，均在中间文件中存储<单词，1>的中间键值对；`Reduce` 函数获取某一单词及其对应的所有键值对，并通过计算键值对的长度获得文件文本中该单词的数目。

### 系统架构及执行流程

![Lab1_figure2](https://github.com/jlu-xiurui/MIT6.824-labs/blob/master/noteFigures/Lab1_figure1.png)

上图为MapReduce系统的基本架构及其执行流程，在系统中由**Master**服务器负责管理系统的各种元数据（如中间文件存储位置、系统输入文件执行位置等），并管理map和reduce任务的执行状态；**Worker**服务器负责对map和reduce任务的实际执行，其通过RPC向**Master**服务器请求任务及其所需的元数据。

MapReduce的任务流程如下所示：

1. 输入文件被划为为若干小文件，文件的个数即为map任务的个数（记为M）、reduce的个数作为系统的参数被定义（即为R），输入文件的存储位置被存放在**Master**服务器中，**Master**服务器选取空闲的**Worker**服务器，并向其分配map任务或reduce任务。在这里的约束条件为：当系统存在未完成的map任务时，所有reduce任务的请求都将被阻塞；
2. 当**Worker**服务器执行map任务时，其从**Master**服务器获取文件的存储位置，并远程（或本地）读取文件，然后将其文件名和文件文本以字符串的形式传入用户map函数，并将用户map函数所生成的键值对存放在内存的缓冲区中。定期地，键值对将被传输到服务器本地的中间文件中（其中中间文件由分区函数被分为用于传给R个reduce任务的R个子文件），并告知**Master**服务器中间文件的存储位置；
3. 当**Worker**服务器执行reduce任务时，其从**Master**服务器获取该任务对应的N个中间文件子文件的存储位置，并远程读取文件。在读取所有文件后，服务器对读取得到的键值对进行排序，然后，其将每一键及其对应的所有值发送至用户reduce函数，并把用户reduce函数的输出存储在本地，并告知**Master**服务器输出文件的存储位置；
4. 当**Master**服务器观察到所有map和reduce函数均执行完毕后，其将唤醒并返回用户程序。

MapReduce系统的一大特点即为其容错机制的简易性。**Master**服务器的运行时崩溃将导致系统直接向用户返回错误，这使得系统不必对**Master**服务器的容错进行设计。同时，**Master**服务器将记录各**Worker**服务器的运行时间，当其发现**Worker**服务器超时时，其就会认为该服务器崩溃，并将该服务器负责的任务收回以发送给其余**Worker**服务器，该机制可以很简单的解决**Worker**服务器的容错。

## 具体代码实现

### 远程过程调用 RPC

在本课程实验所搭建的分布式系统中，远程过程调用（RPC）被用于各服务器的通信。在MapReduce系统中，**Master**服务器将作为RPC的接收方，其通过下述语句在网络中注册自己的服务：

```go
func (c *Coordinator) server() {
	rpc.Register(c)
	rpc.HandleHTTP()
	//l, e := net.Listen("tcp", ":1234")
	sockname := coordinatorSock()
	os.Remove(sockname)
	l, e := net.Listen("unix", sockname)
	if e != nil {
		log.Fatal("listen error:", e)
	}
	go http.Serve(l, nil)
}
```

在这里，**Master**服务器调用`rpc.Register(c)`将`Coordinator`的方法注册在本地服务器，使得RPC发送方可以对其调用；通过`rpc.HandleHTTP()`使得本地服务器可以处理HTTP请求；通过`net.Listen("unix", sockname)`获取套接字，并调用`http.Serve(l, nil)`使得该套接字监听其他服务器的请求。在这里，用于被RPC远程调用的方法应当遵循以下格式：

```go
func (c *Coordinator) Example(args *ExampleArgs, reply *ExampleReply) error {
	reply.Y = args.X + 1
	return nil
}
```

其需要以`error`类型作为返回值，以通知发送方RPC调用是否成功，其参数应当由一个发送方填充的`args`类型指针和一个由接收方填充的`reply`类型指针构成。**Worker**服务器作为RPC调用方，通过以下语句进行RPC调用：

```go
ok := call("Coordinator.Example", &args, &reply)
...
func call(rpcname string, args interface{}, reply interface{}) bool {
	// c, err := rpc.DialHTTP("tcp", "127.0.0.1"+":1234")
	sockname := coordinatorSock()
	c, err := rpc.DialHTTP("unix", sockname)
	if err != nil {
		log.Fatal("dialing:", err)
	}
	defer c.Close()

	err = c.Call(rpcname, args, reply)
	if err == nil {
		return true
	}

	fmt.Println(err)
	return false
}
```

调用RPC时，需要指定需要调用的方法名，并填充`args`类型及创建`reply`类型结构体，在`c, err := rpc.DialHTTP("unix", sockname)`创建套接字后，调用`err = c.Call(rpcname, args, reply)`远程调用方法，在这里，传入`Call`方法的`args`和`reply`的类型是指针类型。

### **Master**服务器

在实验中，`Coordinator`类型将作为系统中的**Master**服务器，在这里，本人在`Coordinator`类型中存储了以下数据：

```go
type Coordinator struct {
	// Your definitions here.
	MapTask      []Task
	ReduceTask   []Task
	Path         string
	FileName     []string
	MapRemain    int
	ReduceRemain int
	mu           sync.Mutex
}
...
// task state
const (
	IDLE        = 0
	IN_PROGRESS = 1
	COMPLETE    = 2
)
type Machine struct {
	Path string
}
type Task struct {
	State         int
	WorkerMachine Machine
	StartTime     time.Time
}
```

其中，`Task`用于记录有关任务的信息：`State`记录任务的运行状态（0 - 空闲、1 - 运行中、2 - 完成）、`WorkerMachine`用于记录服务器在网络中的地址，由于本实验中MapReduce在Unix域下运行，因此仅需记录服务器运行的绝对路径即可，map和reduce任务分别由`MapTask`与`ReduceTask`管理；`Path`存储了服务器运行的绝对路径；`FileName`存储了系统输入的所有子文件的文件名；`MapRemain`和`ReduceRemain分别`记录了当前尚未完成的map和reduce任务数量；`mu`用于保护上述元数据。

```go
func MakeCoordinator(files []string, nReduce int) *Coordinator {
	c := Coordinator{}

	// Your code here.
	nMap := len(files)
	c.MapTask = make([]Task, nMap)
	c.ReduceTask = make([]Task, nReduce)
	path, err := os.Getwd()
	if err != nil {
		log.Fatalf("Getwd failed")
	}
	c.Path = path
	c.FileName = make([]string, nMap)
	c.MapRemain = nMap
	c.ReduceRemain = nReduce
	for i, filename := range files {
		if err != nil {
			log.Fatalf("cannot open %v", filename)
		}
		c.FileName[i] = filename
	}

	c.server()
	return &c
}
```

`MakeCoordinator`初始化**Master**服务器并调用`c.server()`使其开始运行，其中`MapTask`中任务个数与输入子文件的个数相同、`ReduceTask`中任务个数由输入参数规定。

```go
func (c *Coordinator) AskMapTask(args *AskMapArgs, reply *AskMapReply) error {
	// find a map task first, maybe IDLE or timeout
	currTime := time.Now()
	c.mu.Lock()
	defer c.mu.Unlock()
	if c.MapRemain == 0 {
		reply.TaskId = -1
		reply.Over = true
		return nil
	}
	for i, task := range c.MapTask {
		dur := currTime.Sub(c.MapTask[i].StartTime)
		if task.State == IDLE || (task.State == IN_PROGRESS && dur.Seconds() > 10.0) {
			c.MapTask[i].State = IN_PROGRESS
			c.MapTask[i].WorkerMachine = Machine{args.WorkerMachine.Path}
			c.MapTask[i].StartTime = currTime
			reply.Path = c.Path
			reply.Filename = c.FileName[i]
			reply.TaskId = i
			reply.NReduce = len(c.ReduceTask)
			reply.Over = false
			return nil
		}
	}
	reply.Over = false
	reply.TaskId = -1
	return nil
}
...
type AskMapArgs struct {
	WorkerMachine Machine
}

type AskMapReply struct {
	Path     string
	Filename string
	TaskId   int
	NReduce  int
	Over     bool
}
```

当**Worker**服务器向**Master**服务器远程调用`AskMapTask`时，代表**Worker**服务器期望被分配一个map任务。其中**Worker**服务器需要填充其运行地址`WorkerMachine`，**Master**服务器需要返回任务的执行情况（`TaskId` - **Worker**服务器被分配的map任务编号、`NReduce ` - 系统的reduce任务个数、`Over` - 系统是否以及运行完毕所有map任务）、该map任务对应的子文件存储地址（`path` - 服务器运行绝对路径、`Filename` - 文件名）。其执行流程如下：

1. 使用互斥锁保护**Master**服务器元数据；
2. 查看当前是否还有尚未完成的map任务，如无则填充`reply.TaskId = -1`及`reply.Over = true`用于告知**Worker**服务器；
3. 如还有尚未完成的任务，则遍历map任务列表`c.MapTask`，并寻找是否有**状态为空闲**或**状态为进行中但运行超时**的任务。如有则填充列表中该任务项的元数据：将`State`置为` IN_PROGRESS`、将`WorkerMachine`置为**Worker**服务器的运行绝对路径、将`StartTime`置为当前时间`currTime`；同时，填充`reply`结构，将`Path`置为**Master**服务器的运行绝对路径、`Filename`置为该map任务对应的输入子文件文件名、`TaskId`置为该map任务的编号、`Over`置为false表示还有尚未完成的任务。
4. 如还有尚未完成的任务，但无**状态为空闲**或**状态为进行中但运行超时**的任务，则该次请求失败，返回`TaskId`为 - 1、`Over`为false。

```go
func (c *Coordinator) AskReduceTask(args *AskReduceArgs, reply *AskReduceReply) error {
	c.mu.Lock()
	defer c.mu.Unlock()
	if c.ReduceRemain == 0 {
		reply.TaskId = -1
		reply.Over = true
		return nil
	}
	currTime := time.Now()
	for i, task := range c.ReduceTask {
		dur := currTime.Sub(c.ReduceTask[i].StartTime)
		if task.State == IDLE || (task.State == IN_PROGRESS && dur.Seconds() > 10.0) {
			c.ReduceTask[i].State = IN_PROGRESS
			c.ReduceTask[i].WorkerMachine = Machine{args.WorkerMachine.Path}
			c.ReduceTask[i].StartTime = currTime
			for _, task := range c.MapTask {
				reply.IntermediateMachine = append(reply.IntermediateMachine, task.WorkerMachine)
			}
			reply.TaskId = i
			reply.Over = false
			return nil
		}
	}
	reply.TaskId = -1
	reply.Over = false
	return nil
}
...
type AskReduceArgs struct {
	WorkerMachine Machine
}

type AskReduceReply struct {
	IntermediateMachine []Machine
	TaskId              int
	Over                bool
}
```

当**Worker**服务器向**Master**服务器远程调用`AskReduceTask`时，代表**Worker**服务器期望被分配一个reduce任务。其运行逻辑与`AskMapTask`相似，唯一不同的地方在于其需要向**Worker**服务器返回所有执行map任务的**Worker**服务器的执行地址。

```go
func (c *Coordinator) MapOver(args *TaskOverArgs, reply *TaskOverReply) error {
	c.mu.Lock()
	defer c.mu.Unlock()
	i := args.TaskId
	c.MapTask[i].State = COMPLETE
	c.MapRemain--
	//fmt.Printf("map task %d over\n", i)
	return nil
}
...
func (c *Coordinator) ReduceOver(args *TaskOverArgs, reply *TaskOverReply) error {
	c.mu.Lock()
	defer c.mu.Unlock()
	i := args.TaskId
	c.ReduceTask[i].State = COMPLETE
	c.ReduceRemain--
	//fmt.Printf("reduce task %d over\n", i)
	return nil
}
```

当**Worker**服务器向**Master**服务器远程调用`MapOver`或`ReduceOver`时，代表**Worker**服务器已经完成该map或reduce任务。其中**Worker**服务器需要填充其完成map或redece的任务编号，**Master**服务器需要将对应任务的状态置为完成`COMPLETE`，并递减`c.MapRemain`或`c.ReduceRemain`。

### Worker服务器

```go
func Worker(mapf func(string, string) []KeyValue,
	reducef func(string, []string) string) {

	// Your worker implementation here.

	// uncomment to send the Example RPC to the coordinator.
	// CallExample()'
	mapDone := false
	reduceDone := false
	for !mapDone || !reduceDone {
		// try DoMapTask, if OK or cause err, then continue and try another map task
		if !mapDone {
			if ret, Done := DoMapTask(mapf); ret >= 0 {
				args := TaskOverArgs{ret}
				reply := TaskOverReply{}

				for !call("Coordinator.MapOver", &args, &reply) {
				}
				//fmt.Printf("map task %d finished\n", ret)
			} else if Done {
				// DoMapTask return -1, there is a err, just try again, if return over == true,
				// then all map tasks have finished
				mapDone = true
			}
		} else {
			// try DoReduceTask
			if ret, Done := DoReduceTask(reducef); ret >= 0 {
				args := TaskOverArgs{ret}
				reply := TaskOverReply{}
				for !call("Coordinator.ReduceOver", &args, &reply) {
				}
				//fmt.Printf("reduce task %d finished\n", ret)
			} else if Done {
				// DoReduceTask return -1, there is a err, just try again, if return over == true,
				// then all map tasks have finished
				reduceDone = true
			}
		}
	}
}
...
func main() {
	if len(os.Args) != 2 {
		fmt.Fprintf(os.Stderr, "Usage: mrworker xxx.so\n")
		os.Exit(1)
	}

	mapf, reducef := loadPlugin(os.Args[1])

	mr.Worker(mapf, reducef)
}
```

`Worker`为**Worker**服务器执行其任务的核心函数，其参数为用户定义的map和reduce函数，由`loadPlugin`函数读取。该函数循环检查任务完成情况，并向**Master**服务器发送任务请求。其运行流程如下：

1. 开启循环向**Master**服务器发送任务请求，每次循环开始时检查当前map任务和reduce任务是否全部完成，如完成则退出循环；
2. 如果当前map任务尚未全部完成，则调用`DoMapTask`向主服务器请求map任务并执行，其返回值为**<该函数中完成map任务的编号 - ret、map任务是否均成功完成 - done>**。如函数返回的任务编号不为 -1，即表示本次调用完成了一个map任务，则循环调用`Coordinator.MapOver`直到调用成功，以通知**Master**服务器该任务已经完成。如该函数返回`done`值为真，则将`mapDone`置为真表示所有map任务已经全部完成；
3. 如果当前map任务已经全部完成，则调用`DoReduceTask`向主服务器请求reduce任务并执行，其逻辑与执行map任务相同；
4. 如果所有map和reduce任务均已完成，则跳出循环返回。

可以看出，本实验的实现使得**reduce任务必须在所有map任务完成后执行**的约束在**Worker**服务器中被执行，该方法与在**Master**服务器进行约束执行相比，可以使得map任务完成前尝试执行reduce任务的**Worker**服务器不必被RPC阻塞，并可以继续尝试执行可能在其他**Worker**服务器中执行失败的map任务。

```go
func DoMapTask(mapf func(string, string) []KeyValue) (int, bool) {
	// call RPC to get content for Map
	path, err := os.Getwd()
	if err != nil {
		//fmt.Printf("Getwd failed!\n")
		return -1, false
	}
	args := AskMapArgs{Machine{path}}
	reply := AskMapReply{}
	ok := call("Coordinator.AskMapTask", &args, &reply)
	if !ok {
		//fmt.Printf("Call AskMapTask failed!\n")
		return -1, false
	}
	// All Map task is busy or over
	if reply.TaskId == -1 {
		//fmt.Printf("All map task busy or over!\n")
		return -1, reply.Over
	}
	// Do the user Map
	taskId := reply.TaskId
	nReduce := reply.NReduce
	//fmt.Printf("task %d content : %s,filename : %s", taskId, reply.Content, reply.Filename)
	filePath := reply.Path + "/" + reply.Filename
	file, err := os.Open(filePath)
	if err != nil {
		log.Fatalf("cannot open %v", filePath)
	}
	content, err := ioutil.ReadAll(file)
	if err != nil {
		log.Fatalf("cannot read %v", filePath)
	}
	file.Close()
	kva := mapf(reply.Filename, string(content))
	intermediate := make([][]KeyValue, nReduce)
	for _, kv := range kva {
		i := ihash(kv.Key) % nReduce
		intermediate[i] = append(intermediate[i], kv)
	}
	for i := 0; i < nReduce; i++ {
		filename := fmt.Sprintf("mr-%d%d", taskId, i)
		file, _ := os.Create(filename)
		enc := json.NewEncoder(file)
		for _, kv := range intermediate[i] {
			err := enc.Encode(&kv)
			if err != nil {
				//fmt.Printf("Encode failed!\n")
				return -1, false
			}
		}
		file.Close()
	}
	return taskId, false
}
```

`DoMapTask`进行实际的map任务请求和执行，其执行流程如下：

1. 调用`os.Getwd()`得到其执行路径，并向主服务器远程调用`Coordinator.AskMapTask`请求map任务，如调用失败则直接返回< -1 , false>，如主服务器答复的`reply.TaskId == -1`，则代表当前所有任务均完成或均忙，返回< -1 , `reply.Over`>区分该种情况；
2. 如主服务器答复的`reply.TaskId != -1` 则主服务器向该服务器分配了一个编号为`reply.TaskId`的map任务。此时，可通过`reply.Path`与`reply.Filename`获取此map任务对应的系统输入子文件，并将该文件文本及其文件名传入用户定义的map函数，即本函数的输入参数`mapf`，并得到中间键值对数组`kva`；
3. 根据键值对数组`kva`每个元素`kv`的键值`kv.key`，通过哈希算法并对`nReduce`取模，使得键值对可以被均匀的分配至`nReduce`个中间文件中，在这里将应写入`nReduce`个中间文件的键值对存放在`intermediate`数组中；
4. 遍历`intermediate`数组，将每个子数组的键值对通过`json.NewEncoder`写入对应的中间文件中，中间文件的文件名应当为`mr-<map任务编号><intermediate数组索引>`。

```go
func DoReduceTask(reducef func(string, []string) string) (int, bool) {
	// call RPC to get intermediate file for Reduce
	path, err := os.Getwd()
	if err != nil {
		//fmt.Printf("Getwd failed!\n")
		return -1, false
	}
	args := AskReduceArgs{Machine{path}}
	reply := AskReduceReply{}
	ok := call("Coordinator.AskReduceTask", &args, &reply)
	if !ok {
		//fmt.Printf("Call AskReduceTask failed!\n")
		return -1, false
	}
	// All Reduce task is busy or over
	if reply.TaskId == -1 {
		//fmt.Printf("All reduce task busy or over!\n")
		return -1, reply.Over
	}
	// read all intermediate file
	intermediate := []KeyValue{}
	intermediateMachines := reply.IntermediateMachine
	taskId := reply.TaskId
	for i, machine := range intermediateMachines {
		filename := fmt.Sprintf("%s/mr-%d%d", machine.Path, i, taskId)
		file, err := os.Open(filename)
		if err != nil {
			//fmt.Printf("Open %s failed!\n", filename)
			return -1, false
		}
		dec := json.NewDecoder(file)
		for {
			var kv KeyValue
			if err := dec.Decode(&kv); err != nil {
				break
			}
			intermediate = append(intermediate, kv)
		}
	}
	sort.Sort(ByKey(intermediate))

	tmpfile, err := ioutil.TempFile(path, "tmp")
	if err != nil {
		//fmt.Printf("TempFile failed!\n")
		return -1, false
	}
	// call Reduce on each distinct key in intermediate[],
	i := 0
	for i < len(intermediate) {
		j := i + 1
		for j < len(intermediate) && intermediate[j].Key == intermediate[i].Key {
			j++
		}
		values := []string{}
		for k := i; k < j; k++ {
			values = append(values, intermediate[k].Value)
		}
		output := reducef(intermediate[i].Key, values)

		// this is the correct format for each line of Reduce output.
		fmt.Fprintf(tmpfile, "%v %v\n", intermediate[i].Key, output)

		i = j
	}
	newpath := fmt.Sprintf("%s/mr-out-%d", path, taskId)
	err = os.Rename(tmpfile.Name(), newpath)
	if err != nil {
		//fmt.Printf("Rename failed!\n")
		return -1, false
	}
	tmpfile.Close()
	return taskId, false
}
```

`DoReduceTask`进行实际的reduce任务请求和执行，其执行流程如下：

1. 调用`os.Getwd()`得到其执行路径，并向主服务器远程调用`Coordinator.AskReduceTask`请求map任务，如调用失败则直接返回< -1 , false>，如主服务器答复的`reply.TaskId == -1`，则代表当前所有任务均完成或均忙，返回< -1 , `reply.Over`>区分该种情况；
2. 如主服务器答复的`reply.TaskId != -1` 则主服务器向该服务器分配了一个编号为`reply.TaskId`的reduce任务。此时，可通过`reply.IntermediateMachine`得到完成了各map任务的**Worker**服务器运行地址，即中间文件的存放目录名。
3. 当得到中间文件的存放目录名时，即可得到`<存放目录名>/mr-<map任务编号><reduce任务编号>`格式的该reduce任务对应中间文件的绝对路径，并通过`json.NewDecoder`将上述中间文件的键值对读入`intermediate`。在全部文件读入后，调用`sort.Sort(ByKey(intermediate))`对`intermediate`数组按键进行排序；
4. 在排序结束后，就可以方便的提取键相同的所有键值对，将键及该键对应的所有键值对传入用户定义的reduce函数`reducef`，并将返回结果写入临时文件中，使得主服务器无法观察到部分完成的输出文件，该临时文件通过`ioutil.TempFile`创建；
5. 在输出文件全部构建完毕时，将该临时文件重命名为`mr-out-<reduce任务编号>`。

## 实验结果

```shell
bash test-mr-many.sh 5
...
build 6.824/main: cannot load 6.824/diskv: cannot find module providing package 6.824/diskv
*** Starting wc test.
2022/10/05 16:33:59 rpc.Register: method "Done" has 1 input parameters; needs exactly three
--- wc test: PASS
*** Starting indexer test.
2022/10/05 16:34:09 rpc.Register: method "Done" has 1 input parameters; needs exactly three
--- indexer test: PASS
*** Starting map parallelism test.
2022/10/05 16:34:14 rpc.Register: method "Done" has 1 input parameters; needs exactly three
--- map parallelism test: PASS
*** Starting reduce parallelism test.
2022/10/05 16:34:22 rpc.Register: method "Done" has 1 input parameters; needs exactly three
--- reduce parallelism test: PASS
*** Starting job count test.
2022/10/05 16:34:31 rpc.Register: method "Done" has 1 input parameters; needs exactly three
--- job count test: PASS
*** Starting early exit test.
2022/10/05 16:34:48 rpc.Register: method "Done" has 1 input parameters; needs exactly three
--- early exit test: PASS
*** Starting crash test.
2022/10/05 16:34:56 rpc.Register: method "Done" has 1 input parameters; needs exactly three
--- crash test: PASS
*** PASSED ALL TESTS
build 6.824/main: cannot load 6.824/diskv: cannot find module providing package 6.824/diskv
*** Starting wc test.
2022/10/05 16:35:54 rpc.Register: method "Done" has 1 input parameters; needs exactly three
--- wc test: PASS
*** Starting indexer test.
2022/10/05 16:36:04 rpc.Register: method "Done" has 1 input parameters; needs exactly three
--- indexer test: PASS
*** Starting map parallelism test.
2022/10/05 16:36:09 rpc.Register: method "Done" has 1 input parameters; needs exactly three
--- map parallelism test: PASS
*** Starting reduce parallelism test.
2022/10/05 16:36:17 rpc.Register: method "Done" has 1 input parameters; needs exactly three
--- reduce parallelism test: PASS
*** Starting job count test.
2022/10/05 16:36:26 rpc.Register: method "Done" has 1 input parameters; needs exactly three
--- job count test: PASS
*** Starting early exit test.
2022/10/05 16:36:44 rpc.Register: method "Done" has 1 input parameters; needs exactly three
--- early exit test: PASS
*** Starting crash test.
2022/10/05 16:36:52 rpc.Register: method "Done" has 1 input parameters; needs exactly three
--- crash test: PASS
*** PASSED ALL TESTS
*** PASSED ALL 5 TESTING TRIALS
```

